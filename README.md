<!--
Credits and references used in this README:

1) Layout ideas and section inspiration:
   https://github.com/abhisheknaiidu/awesome-github-profile-readme?tab=readme-ov-file#descriptive-

2) Skill icons (SVG badges):
   https://github.com/tandpfun/skill-icons?tab=readme-ov-file#icons-list

3) GitHub stats card:
   https://github.com/anuraghazra/github-readme-stats
-->

# ðŸ¤– Anusha Challa
**`Data Scientist | AI Researcher (HRI + Trust Modeling) | MS AI(Thesis) Graduate @ University of Georgia 25`**

## About Me
- I am a Data Scientist and AI Researcher focused on **trust-aware AI** for **humanâ€“robot collaboration**.
- At UGA (THINC Lab), I build **VR-based HRI testbeds** and develop **probabilistic models** to understand and predict human behavior.
- I enjoy turning research into clean, reusable code with clear experiments, evaluation, and results.
---

## Skill stack
<!-- Skill icons provided by skillicons.dev -->
[![My Skills](https://skillicons.dev/icons?i=python,r,pytorch,tensorflow,sklearn,opencv,unity,git,github,java,sql&theme=light)](https://skillicons.dev)

**Also comfortable with**: Hugging Face, Pandas/NumPy, Tableau/Power BI, reinforcement learning, Bayesian/probabilistic modeling, experiment design, evaluation & reporting.

---

<h2>Projects - showcase</h2>

<table>
  <tr>
    <td align="center" width="33%">
      <a href="https://github.com/challaanusha46/VR_HRI_I-P">
        <img src="assets/vr_hri_ui.png" alt="VR Humanâ€“AI Trust Testbed UI" height="200" />
      </a>
      <br/>
      <b>VR Humanâ€“AI Trust Testbed</b><br/>
      <sub>Unity + Python VR environment to study trust, transparency, and decision-making in HRI.</sub><br/>
      ðŸ”— <a href="https://github.com/challaanusha46/VR_HRI_I-P">Repo</a><br/>
      <sub>Tags: Unity, HRI, Trust Modeling</sub>
    </td>
    <td align="center" width="33%">
      <a href="https://github.com/challaanusha46/Bias-Human-MDP">
        <img src="assets/bias_human_mdp_pipeline.png" alt="Bias-Aware Human MDP Pipeline" height="200" />
      </a>
      <br/>
      <b>Bias-Aware Human MDP</b><br/>
      <sub>Behavior-log parsing and decision modeling for bias-aware policy reasoning in HRI tasks.</sub><br/>
      ðŸ”— <a href="https://github.com/challaanusha46/Bias-Human-MDP">Repo</a><br/>
      <sub>Tags: MDP, Bayesian Modeling, Research</sub>
    </td>
    <td align="center" width="33%">
      <a href="https://github.com/challaanusha46/RL-assign">
        <img src="assets/rl_uav_grid.png" alt="Reinforcement Learning Simulation" height="200" />
      </a>
      <br/>
      <b>Reinforcement Learning Experiments</b><br/>
      <sub>RL implementations with simulation demos, training runs, and evaluation outputs.</sub><br/>
      ðŸ”— <a href="https://github.com/challaanusha46/RL-assign">Repo</a><br/>
      <sub>Tags: RL, Python, Simulation</sub>
    </td>
  </tr>
</table>

---
## Publications
- [**A Novel Computational Framework of Robot Trust for Human-Robot Teams** (ICRA 2025)](http://thinc.cs.uga.edu/files/nfdcjICRA25.pdf)

- [**A Computational Model of Robot Trust for Human-Robot Teams** (ARMS @ AAMAS 2024)](http://thinc.cs.uga.edu/files/nfcdcARMS2024.pdf)

- [**A new MCDM approach integrating QFD, DEMATEL with TOPSIS for exploring the effect of social network usage on academic performance**](https://www.researchgate.net/publication/305250877_A_new_MCDM_approach_integrating_QFD_dematel_with_topsis_for_exploring_the_effect_of_social_network_usage_on_academic_performance)
  
- **Google Scholar**  
  - https://scholar.google.com/citations?pli=1&authuser=2&user=Y9kL_HUAAAAJ
---


## Links
- [**LinkedIn**](https://www.linkedin.com/in/challaanusha/)
- [**GitHub**](https://github.com/challaanusha46)
- [**Contact**](mailto:anusha.challaac@gmail.com)

<a href="https://www.linkedin.com/in/challaanusha/" target="blank">
  <img src="https://skillicons.dev/icons?i=linkedin" alt="LinkedIn" />
</a>
<a href="mailto:anusha.challaac@gmail.com" target="blank">
  <img src="https://skillicons.dev/icons?i=gmail" alt="Email" />
</a>

