<!--
Credits and references used in this README:

1) Layout ideas and section inspiration:
   https://github.com/abhisheknaiidu/awesome-github-profile-readme?tab=readme-ov-file#descriptive-

2) Skill icons (SVG badges):
   https://github.com/tandpfun/skill-icons?tab=readme-ov-file#icons-list

3) GitHub stats card:
   https://github.com/anuraghazra/github-readme-stats
-->

# ðŸ¤– Anusha Challa
**`Data Scientist | AI Researcher (HRI + Trust Modeling) | MS AI @ University of Georgia`**

## About Me
- I work on **trust-aware AI** for **humanâ€“robot collaboration**, combining research with practical ML engineering.
- Graduate Research Assistant at UGA (THINC Lab) focused on **behavioral modeling**, **probabilistic trust inference**, and **VR-based HRI testbeds**.
- Previously built and delivered enterprise systems in insurance/finance using **Pega PRPC**, APIs, and workflow automation.

---

## Skill stack
<!-- Skill icons provided by skillicons.dev -->
[![My Skills](https://skillicons.dev/icons?i=python,r,pytorch,tensorflow,sklearn,opencv,unity,git,github,java,sql&theme=light)](https://skillicons.dev)

**Also comfortable with**: Hugging Face, Pandas/NumPy, Tableau/Power BI, reinforcement learning, Bayesian/probabilistic modeling, experiment design, evaluation & reporting.

---

## Projects - showcase

<table>
  <tr>
    <td align="center" width="33%">
      <a href="https://github.com/challaanusha46/VR_HRI_I-P">
        <img src="assets/vr_hri_ui.png"
             alt="VR Humanâ€“AI Trust Testbed UI"
             style="width:100%; height:200px; object-fit:cover;"/>
      </a>
      <br/>
      <b>VR Humanâ€“AI Trust Testbed</b><br/>
      <sub>Unity + Python VR environment to study trust, transparency, and decision-making in HRI.</sub><br/>
      ðŸ”— <a href="https://github.com/challaanusha46/VR_HRI_I-P">Repo</a>
      <br/>
      <sub>Tags: Unity, HRI, Trust Modeling</sub>
    </td>

    <td align="center" width="33%">
      <a href="https://github.com/challaanusha46/Bias-Human-MDP">
        <img src="assets/bias_human_mdp_pipeline.png"
             alt="Bias-Aware Human MDP Pipeline"
             style="width:100%; height:200px; object-fit:cover;"/>
      </a>
      <br/>
      <b>Bias-Aware Human MDP</b><br/>
      <sub>Behavior-log parsing and decision modeling for bias-aware policy reasoning in HRI tasks.</sub><br/>
      ðŸ”— <a href="https://github.com/challaanusha46/Bias-Human-MDP">Repo</a>
      <br/>
      <sub>Tags: MDP, Bayesian Modeling, Research</sub>
    </td>

    <td align="center" width="33%">
      <a href="https://github.com/challaanusha46/RL-assign">
        <img src="assets/rl_uav_grid.png"
             alt="Reinforcement Learning Simulation"
             style="width:100%; height:200px; object-fit:cover;"/>
      </a>
      <br/>
      <b>Reinforcement Learning Experiments</b><br/>
      <sub>RL implementations with simulation demos, training runs, and evaluation outputs.</sub><br/>
      ðŸ”— <a href="https://github.com/challaanusha46/RL-assign">Repo</a>
      <br/>
      <sub>Tags: RL, Python, Simulation</sub>
    </td>
  </tr>
</table>

---

## Publications
- **A Novel Computational Framework of Robot Trust for Human-Robot Teams** â€” IEEE ICRA 2025 (Oral)
- **A Computational Model of Robot Trust for Human-Robot Teams** â€” ARMS Workshop, AAMAS 2024

---

## Stats
![Anusha's GitHub stats](https://github-readme-stats.vercel.app/api?username=challaanusha46&show_icons=true&theme=gruvbox)

---

## Links
- [**LinkedIn**](https://www.linkedin.com/in/challaanusha/)
- [**GitHub**](https://github.com/challaanusha46)
- [**Contact**](mailto:anusha.challaac@gmail.com)

<a href="https://www.linkedin.com/in/challaanusha/" target="blank">
  <img src="https://skillicons.dev/icons?i=linkedin" alt="LinkedIn" />
</a>
<a href="mailto:anusha.challaac@gmail.com" target="blank">
  <img src="https://skillicons.dev/icons?i=gmail" alt="Email" />
</a>

